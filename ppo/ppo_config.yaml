# Basic ppo specific config
---

# sub param for icm
use_icm: false
icm_phi: 'config.phi'
icm_gradient_clipping: 1.5

# sub param for drq
drq_padding: 2
drq_augment_num: 1 # excluding original state

# loss clipping
loss_actor_clip_value: null # number or null
loss_critic_clip_value: null # number or null
entropy_clip_value: null # number or null
loss_clip_value: null # number or null


# cheet reward
linear_negative_reward_drop_steps: -1
use_reward_discount: true


track_progress_success_threshold: 10
max_episode_len: 500


update_every_n_steps: 5000
learning_updates_per_learning_session: 1

discount_rate: 0.99
eps_clip: 0.2  # clip parameter for PPO

# parameters for Adam optimizer
lr: 0.0001
gradient_clipping_norm: 0.1
betas: [0.9, 0.999]
...